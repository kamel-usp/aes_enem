{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, mean_squared_error\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "from lightning.pytorch.core.module import LightningModule\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from lightning.pytorch.callbacks import Callback\n",
    "from lightning.pytorch.trainer import Trainer\n",
    "from lightning.pytorch.loggers.csv_logs import CSVLogger\n",
    "from coral_pytorch.losses import corn_loss\n",
    "from coral_pytorch.dataset import corn_label_from_logits\n",
    "import os\n",
    "\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "REFERENCE_CONCEPT = 0\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE=16\n",
    "WEIGHT_DECAY=0.01\n",
    "GRADIENT_ACC = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "PRECISION = \"16-mixed\"\n",
    "OBJECTIVE = \"classification\"\n",
    "VARIANT = \"base\"\n",
    "TOKENIZER_NAME = f\"neuralmind/bert-{VARIANT}-portuguese-cased\"\n",
    "MODEL_NAME = f\"kamel-usp/aes_enem_models-sourceB-ordinal-{VARIANT}-C{REFERENCE_CONCEPT+1}\"\n",
    "BASE_MODEL = \"sourceB-ordinal\"\n",
    "EXPERIMENT_NAME = f\"aes_enem_models-sourceA-{OBJECTIVE}-from-{BASE_MODEL}-{VARIANT}-C{REFERENCE_CONCEPT+1}\"\n",
    "\n",
    "pl.seed_everything(RANDOM_SEED)\n",
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Couldn't reach 'kamel-usp/aes_enem_dataset' on the Hub (ConnectionError)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkamel-usp/aes_enem_dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msourceAWithGraders\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/tmp/aes_enem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/aes_enem/lib/python3.11/site-packages/datasets/load.py:2128\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2123\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[1;32m   2124\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[1;32m   2125\u001b[0m )\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2128\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2140\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2143\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[1;32m   2144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[0;32m~/miniconda3/envs/aes_enem/lib/python3.11/site-packages/datasets/load.py:1814\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   1812\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[1;32m   1813\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 1814\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1820\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1821\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[1;32m   1823\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/aes_enem/lib/python3.11/site-packages/datasets/load.py:1511\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1506\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[1;32m   1507\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1508\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1509\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1510\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1511\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1515\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/aes_enem/lib/python3.11/site-packages/datasets/load.py:1467\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# noqa catch any exception of hf_hub and consider that the dataset doesn't exist\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1460\u001b[0m         e,\n\u001b[1;32m   1461\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1465\u001b[0m         ),\n\u001b[1;32m   1466\u001b[0m     ):\n\u001b[0;32m-> 1467\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hub (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1468\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m404\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[1;32m   1469\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mConnectionError\u001b[0m: Couldn't reach 'kamel-usp/aes_enem_dataset' on the Hub (ConnectionError)"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"kamel-usp/aes_enem_dataset\", \"sourceAWithGraders\", cache_dir=\"/tmp/aes_enem\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d959e7ab314c96a0e0a2ee4f6a3521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/744 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b562e57d392412d88d359a0440616da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/195 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ee5bef699f40f29a84c58571adaa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/216 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grade_mapping = {\n",
    "    0: 0,\n",
    "    40: 1,\n",
    "    80: 2,\n",
    "    120: 3,\n",
    "    160: 4,\n",
    "    200: 5,\n",
    "}\n",
    "\n",
    "def create_label(row):\n",
    "    grade = row[\"grades\"][REFERENCE_CONCEPT]\n",
    "    return {\"label\": grade_mapping[grade]}\n",
    "\n",
    "dataset = dataset.map(create_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_difference(lists):\n",
    "    # Assuming the first element is the reference for subtraction\n",
    "    reference = lists[0][REFERENCE_CONCEPT]\n",
    "    grader_a = lists[1][REFERENCE_CONCEPT]\n",
    "    grader_b = lists[2][REFERENCE_CONCEPT]\n",
    "\n",
    "    # Calculate absolute differences\n",
    "    diff_ref_a = abs(reference - grader_a)\n",
    "    diff_ref_b = abs(reference - grader_b)\n",
    "    diff_a_b = abs(grader_a - grader_b)\n",
    "\n",
    "    # Check if any difference is greater than 80\n",
    "    return diff_ref_a > 80 or diff_ref_b > 80 or diff_a_b > 80\n",
    "\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "new_test_df = pd.merge(\n",
    "    test_df.groupby([\"id_prompt\", \"id\"]).agg({\"grades\": list}).apply(lambda x: compute_difference(x['grades']), axis=1).reset_index(),\n",
    "    test_df,\n",
    "    on=[\"id_prompt\",\"id\"]\n",
    ").rename(columns={0: \"is_hard\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"test_easy\"] = Dataset.from_pandas(new_test_df[new_test_df[\"is_hard\"]==False])\n",
    "dataset[\"test_hard\"] = Dataset.from_pandas(new_test_df[new_test_df[\"is_hard\"]==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, use_fast=True)\n",
    "if OBJECTIVE == \"regression\":\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME, \n",
    "            cache_dir=\"/tmp/\", \n",
    "            num_labels=1,\n",
    "        )\n",
    "elif OBJECTIVE == \"classification\" or OBJECTIVE == \"ordinal\":\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME, \n",
    "            cache_dir=\"/tmp/\", \n",
    "            num_labels=6,\n",
    "        )\n",
    "else:\n",
    "    raise ValueError(\"Please set a Pre defined Objectice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    def tokenize_essays(dataset, tokenizer, max_length=512):\n",
    "        tokenized_text = tokenizer(\n",
    "                dataset[\"essay_text\"],\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                padding=\"max_length\",\n",
    "                max_length=max_length\n",
    "            )\n",
    "        tokenized_text[\"label\"] = dataset[\"label\"]\n",
    "        return tokenized_text\n",
    "    \n",
    "    tokenized_datasets = {\n",
    "        split: tokenize_essays(sub_dataset, tokenizer, MAX_LENGTH)\n",
    "        for split, sub_dataset in dataset.items()\n",
    "    }\n",
    "    dataset_tokenized = DatasetDict({\n",
    "        split: Dataset.from_dict(data)\n",
    "        for split, data in tokenized_datasets.items()\n",
    "    })\n",
    "\n",
    "    return dataset_tokenized\n",
    "\n",
    "dataset_tokenized = prepare_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = DataLoader(\n",
    "    dataset_tokenized[\"train\"].with_format(\"torch\"), batch_size=BATCH_SIZE, shuffle=True, num_workers=0\n",
    ")\n",
    "data_val = DataLoader(dataset_tokenized[\"validation\"].with_format(\"torch\"), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "data_test = DataLoader(dataset_tokenized[\"test\"].with_format(\"torch\"), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "data_test_easy = DataLoader(dataset_tokenized[\"test_easy\"].with_format(\"torch\"), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "data_test_hard = DataLoader(dataset_tokenized[\"test_hard\"].with_format(\"torch\"), batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7815b0e71b474b1889e95cef3ca42db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict_classes(output):\n",
    "    if OBJECTIVE == \"regression\":\n",
    "        # Round the tensor to the nearest integer\n",
    "        rounded_tensor = torch.round(output.logits)\n",
    "        # Clamp the values to the range [0, 5]\n",
    "        clamped_tensor = torch.clamp(rounded_tensor, min=0, max=5)\n",
    "        return clamped_tensor.view(-1)\n",
    "    elif OBJECTIVE == \"classification\":\n",
    "        return torch.argmax(output.logits, axis=1)\n",
    "    elif OBJECTIVE == \"ordinal\":\n",
    "        return corn_label_from_logits(output.logits)\n",
    "        \n",
    "def get_predictions_and_labels(model, dataloader):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    i=0\n",
    "    for batch in tqdm(dataloader, desc=\"Obtaining predictions\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_ids, attention_mask)\n",
    "            predicted_classes = predict_classes(output) \n",
    "\n",
    "        # If using GPU, need to move the data back to CPU to use numpy.\n",
    "        all_predictions.extend(predicted_classes.cpu().numpy())\n",
    "        all_true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return list(map(lambda x: x * 40, all_predictions)), list(map(lambda x: x * 40, all_true_labels))\n",
    "\n",
    "all_predictions, all_true_labels = get_predictions_and_labels(model, data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enem_accuracy_score(true_values, predicted_values):\n",
    "    assert len(true_values) == len(predicted_values), \"Mismatched length between true and predicted values.\"\n",
    "\n",
    "    non_divergent_count = sum([1 for t, p in zip(true_values, predicted_values) if abs(t - p) <= 80])\n",
    "    \n",
    "    return non_divergent_count / len(true_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation  set: 0.46\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "print(f\"Accuracy on the validation  set: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QWK on the validation set: 0.28\n"
     ]
    }
   ],
   "source": [
    "qwk = cohen_kappa_score(all_true_labels, all_predictions, weights=\"quadratic\", labels=[0,40,80,120,160,200])\n",
    "print(f\"QWK on the validation set: {qwk:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the validation set: 0.94\n"
     ]
    }
   ],
   "source": [
    "enem_accuracy = enem_accuracy_score(all_true_labels, all_predictions)\n",
    "print(f\"Accuracy on the validation set: {enem_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningGradePredictor(LightningModule):\n",
    "    def __init__(self, model: nn.Module, loss_function, learning_rate=0.001, num_warmup_steps=None, num_training_steps=None):\n",
    "        super(LightningGradePredictor, self).__init__()\n",
    "        self.model = model\n",
    "        self.loss = loss_function\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        self.num_training_steps = num_training_steps\n",
    "        self.save_hyperparameters(ignore=['model'])\n",
    "        self.training_step_loss = []\n",
    "        self.validation_step_loss = []\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"label\"]\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = None\n",
    "        if OBJECTIVE == \"regression\":\n",
    "            loss = self.loss(outputs.logits, labels.unsqueeze(1).float())\n",
    "        elif OBJECTIVE == \"classification\":\n",
    "            loss = self.loss(outputs.logits, labels)\n",
    "        elif OBJECTIVE == \"ordinal\":\n",
    "            loss = self.loss(outputs.logits, labels, num_classes=self.model.num_labels)\n",
    "        self.log('train_loss', loss)\n",
    "        self.training_step_loss.append(loss)\n",
    "        optimizer = self.optimizers()\n",
    "        if isinstance(optimizer, list):\n",
    "            optimizer = optimizer[0]\n",
    "        lr_current = optimizer.optimizer.param_groups[0]['lr']\n",
    "        self.log('current_lr', lr_current)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"label\"]\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        if OBJECTIVE == \"regression\":\n",
    "            loss = self.loss(outputs.logits, labels.unsqueeze(1).float())\n",
    "        elif OBJECTIVE == \"classification\":\n",
    "            loss = self.loss(outputs.logits, labels)\n",
    "        elif OBJECTIVE == \"ordinal\":\n",
    "            loss = self.loss(outputs.logits, labels, num_classes=self.model.num_labels)\n",
    "        self.log('val_loss', loss)\n",
    "        self.validation_step_loss.append(loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch[\"input_ids\"], batch[\"attention_mask\"], batch[\"label\"]\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        if OBJECTIVE == \"regression\":\n",
    "            loss = self.loss(outputs.logits,  labels.unsqueeze(1).float())\n",
    "        elif OBJECTIVE == \"classification\":\n",
    "            loss = self.loss(outputs.logits, labels)\n",
    "        elif OBJECTIVE == \"ordinal\":\n",
    "            loss = self.loss(outputs.logits, labels, num_classes=self.model.num_labels)\n",
    "        self.log('test_loss', loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.learning_rate, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        scheduler = get_cosine_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=self.num_warmup_steps,\n",
    "            num_training_steps=self.num_training_steps\n",
    "        )\n",
    "\n",
    "        return [optimizer], [{\"scheduler\": scheduler, \"interval\": \"step\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochEndCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.metrics_df = pd.DataFrame(columns=\n",
    "                                       ['Epoch', 'Train Loss', 'Validation Loss',\n",
    "                                         'Train QWK', 'Validation QWK',\n",
    "                                         'Train RMSE', 'Validation RMSE'\n",
    "                                        ])\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        current_epoch = trainer.current_epoch\n",
    "        # Metrics for training data\n",
    "        train_dataloader = trainer.train_dataloader\n",
    "        val_dataloader = trainer.val_dataloaders\n",
    "        \n",
    "        epoch_train_loss_mean = torch.stack(pl_module.training_step_loss).mean()\n",
    "        epoch_val_loss_mean = torch.stack(pl_module.validation_step_loss).mean()\n",
    "        pl_module.training_step_loss.clear()\n",
    "        pl_module.validation_step_loss.clear()\n",
    "        model.eval()\n",
    "        train_predictions, train_true_labels = get_predictions_and_labels(model, train_dataloader)\n",
    "        val_predictions, val_true_labels = get_predictions_and_labels(model, val_dataloader)\n",
    "        train_qwk = cohen_kappa_score(train_true_labels, train_predictions, weights=\"quadratic\", labels=[0,40,80,120,160,200])\n",
    "        val_qwk = cohen_kappa_score(val_true_labels, val_predictions, weights=\"quadratic\", labels=[0,40,80,120,160,200])\n",
    "        pl_module.log('val_qwk', val_qwk)\n",
    "\n",
    "        train_rmse = mean_squared_error(train_true_labels, train_predictions)\n",
    "        val_rmse = mean_squared_error(val_true_labels, val_predictions)\n",
    "        train_rmse = np.sqrt(train_rmse)\n",
    "        val_rmse = np.sqrt(val_rmse)\n",
    "        pl_module.log('val_rmse', val_rmse)\n",
    "\n",
    "        new_row = {'Epoch': current_epoch, \n",
    "                    'Train Loss': epoch_train_loss_mean.cpu().detach().numpy(),\n",
    "                    'Validation Loss': epoch_val_loss_mean.cpu().detach().numpy(),\n",
    "                    'Train QWK': train_qwk,\n",
    "                    'Validation QWK': val_qwk,\n",
    "                    'Train RMSE': train_rmse,\n",
    "                    'Validation RMSE': val_rmse\n",
    "                    }\n",
    "        new_row = pd.Series(new_row).to_frame().T\n",
    "        self.metrics_df = pd.concat([self.metrics_df, new_row])\n",
    "        display(self.metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_qwk\", patience=3, verbose=True, mode=\"max\")\n",
    "checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"val_qwk\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "def get_loss():\n",
    "    if OBJECTIVE == \"regression\":\n",
    "        return torch.nn.functional.mse_loss\n",
    "    elif OBJECTIVE == \"classification\":\n",
    "        return torch.nn.functional.cross_entropy\n",
    "    elif OBJECTIVE == \"ordinal\":\n",
    "        return corn_loss\n",
    "       \n",
    "loss_function = get_loss() \n",
    "NUM_EPOCHS = 20\n",
    "num_training_steps = NUM_EPOCHS * len(data_train)\n",
    "warmup_steps = int(num_training_steps * 0.1)\n",
    "steps_per_epoch = num_training_steps//NUM_EPOCHS\n",
    "model.train()\n",
    "trainer = Trainer(\n",
    "    max_epochs=NUM_EPOCHS, \n",
    "    log_every_n_steps=steps_per_epoch, \n",
    "    logger=CSVLogger(\"model_logs\", name=EXPERIMENT_NAME), \n",
    "    callbacks=[EpochEndCallback(), early_stop_callback, checkpoint_callback],\n",
    "    precision=PRECISION,\n",
    "    accumulate_grad_batches=GRADIENT_ACC\n",
    "    )\n",
    "ligthning_model = LightningGradePredictor(model, \n",
    "                    loss_function=loss_function,\n",
    "                    num_training_steps=num_training_steps,\n",
    "                    num_warmup_steps=warmup_steps,\n",
    "                    learning_rate = LEARNING_RATE\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: model_logs/aes_enem_models-sourceA-ordinal-from-sourceB-ordinal-base-C5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                          | Params\n",
      "--------------------------------------------------------\n",
      "0 | model | BertForSequenceClassification | 108 M \n",
      "--------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "435.711   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b60f4b05b6f4dfaae28d59535986c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrebarbosa/miniconda3/envs/aes_enem/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/andrebarbosa/miniconda3/envs/aes_enem/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052ca553df5f42fa9c41e7f07f1fe863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914bfb3b9966487fb9bd1ce548043240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe405c682ef4f75b2492eb2f05c8fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e14a6ad96f5464e9cf7668e2d377e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Train QWK</th>\n",
       "      <th>Validation QWK</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.57109076</td>\n",
       "      <td>0.6423257</td>\n",
       "      <td>0.498858</td>\n",
       "      <td>0.286512</td>\n",
       "      <td>48.725697</td>\n",
       "      <td>58.212696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch  Train Loss Validation Loss Train QWK Validation QWK Train RMSE  \\\n",
       "0     0  0.57109076       0.6423257  0.498858       0.286512  48.725697   \n",
       "\n",
       "  Validation RMSE  \n",
       "0       58.212696  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_qwk improved. New best score: 0.287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffae04917df14d8591243297fbcfb373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4240135cb94947a3be395709432fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d86951fbff047db8d15d26f786aa2fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Train QWK</th>\n",
       "      <th>Validation QWK</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.57109076</td>\n",
       "      <td>0.6423257</td>\n",
       "      <td>0.498858</td>\n",
       "      <td>0.286512</td>\n",
       "      <td>48.725697</td>\n",
       "      <td>58.212696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.46558607</td>\n",
       "      <td>0.55239934</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>45.365896</td>\n",
       "      <td>54.500059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch  Train Loss Validation Loss Train QWK Validation QWK Train RMSE  \\\n",
       "0     0  0.57109076       0.6423257  0.498858       0.286512  48.725697   \n",
       "0     1  0.46558607      0.55239934    0.6764       0.429161  45.365896   \n",
       "\n",
       "  Validation RMSE  \n",
       "0       58.212696  \n",
       "0       54.500059  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_qwk improved by 0.143 >= min_delta = 0.0. New best score: 0.429\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202520509719499483087f51f0d3dc02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea652a0862fd4c7fae434f49ad75cb9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8d1d0bb6c034fb4be7a9f4070fa2980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Train QWK</th>\n",
       "      <th>Validation QWK</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.57109076</td>\n",
       "      <td>0.6423257</td>\n",
       "      <td>0.498858</td>\n",
       "      <td>0.286512</td>\n",
       "      <td>48.725697</td>\n",
       "      <td>58.212696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.46558607</td>\n",
       "      <td>0.55239934</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>45.365896</td>\n",
       "      <td>54.500059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43214744</td>\n",
       "      <td>0.5861577</td>\n",
       "      <td>0.632701</td>\n",
       "      <td>0.373088</td>\n",
       "      <td>46.25781</td>\n",
       "      <td>55.247694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch  Train Loss Validation Loss Train QWK Validation QWK Train RMSE  \\\n",
       "0     0  0.57109076       0.6423257  0.498858       0.286512  48.725697   \n",
       "0     1  0.46558607      0.55239934    0.6764       0.429161  45.365896   \n",
       "0     2  0.43214744       0.5861577  0.632701       0.373088   46.25781   \n",
       "\n",
       "  Validation RMSE  \n",
       "0       58.212696  \n",
       "0       54.500059  \n",
       "0       55.247694  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9d38a21ee8404396a4bd3078ca446f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fb90df1fd64151b1b39444a318aed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6eb9d82d1446718a31d9932aea5f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Train QWK</th>\n",
       "      <th>Validation QWK</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.57109076</td>\n",
       "      <td>0.6423257</td>\n",
       "      <td>0.498858</td>\n",
       "      <td>0.286512</td>\n",
       "      <td>48.725697</td>\n",
       "      <td>58.212696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.46558607</td>\n",
       "      <td>0.55239934</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>45.365896</td>\n",
       "      <td>54.500059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43214744</td>\n",
       "      <td>0.5861577</td>\n",
       "      <td>0.632701</td>\n",
       "      <td>0.373088</td>\n",
       "      <td>46.25781</td>\n",
       "      <td>55.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4116666</td>\n",
       "      <td>0.5732384</td>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.399249</td>\n",
       "      <td>44.091791</td>\n",
       "      <td>55.02447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch  Train Loss Validation Loss Train QWK Validation QWK Train RMSE  \\\n",
       "0     0  0.57109076       0.6423257  0.498858       0.286512  48.725697   \n",
       "0     1  0.46558607      0.55239934    0.6764       0.429161  45.365896   \n",
       "0     2  0.43214744       0.5861577  0.632701       0.373088   46.25781   \n",
       "0     3   0.4116666       0.5732384  0.705568       0.399249  44.091791   \n",
       "\n",
       "  Validation RMSE  \n",
       "0       58.212696  \n",
       "0       54.500059  \n",
       "0       55.247694  \n",
       "0        55.02447  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823b2f9306894e59b9ebbd3498a5c1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d2f525866441b88a93d12af2e31182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44593dd31fd244a7af3e4d367a62358e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Train QWK</th>\n",
       "      <th>Validation QWK</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Validation RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.57109076</td>\n",
       "      <td>0.6423257</td>\n",
       "      <td>0.498858</td>\n",
       "      <td>0.286512</td>\n",
       "      <td>48.725697</td>\n",
       "      <td>58.212696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.46558607</td>\n",
       "      <td>0.55239934</td>\n",
       "      <td>0.6764</td>\n",
       "      <td>0.429161</td>\n",
       "      <td>45.365896</td>\n",
       "      <td>54.500059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.43214744</td>\n",
       "      <td>0.5861577</td>\n",
       "      <td>0.632701</td>\n",
       "      <td>0.373088</td>\n",
       "      <td>46.25781</td>\n",
       "      <td>55.247694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.4116666</td>\n",
       "      <td>0.5732384</td>\n",
       "      <td>0.705568</td>\n",
       "      <td>0.399249</td>\n",
       "      <td>44.091791</td>\n",
       "      <td>55.02447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.37811443</td>\n",
       "      <td>0.64613014</td>\n",
       "      <td>0.675218</td>\n",
       "      <td>0.319549</td>\n",
       "      <td>44.334991</td>\n",
       "      <td>55.912019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch  Train Loss Validation Loss Train QWK Validation QWK Train RMSE  \\\n",
       "0     0  0.57109076       0.6423257  0.498858       0.286512  48.725697   \n",
       "0     1  0.46558607      0.55239934    0.6764       0.429161  45.365896   \n",
       "0     2  0.43214744       0.5861577  0.632701       0.373088   46.25781   \n",
       "0     3   0.4116666       0.5732384  0.705568       0.399249  44.091791   \n",
       "0     4  0.37811443      0.64613014  0.675218       0.319549  44.334991   \n",
       "\n",
       "  Validation RMSE  \n",
       "0       58.212696  \n",
       "0       54.500059  \n",
       "0       55.247694  \n",
       "0        55.02447  \n",
       "0       55.912019  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_qwk did not improve in the last 3 records. Best score: 0.429. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=ligthning_model, train_dataloaders=data_train, val_dataloaders=data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = \"model_logs/aes_enem_models-sourceA-from-bertimbau-base/version_0/checkpoints/epoch=7-step=376.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db17375ac7e4ca18691a268628329b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation set:  125.4816\n"
     ]
    }
   ],
   "source": [
    "best_model = LightningGradePredictor.load_from_checkpoint(tmp, \n",
    "                                                  model=ligthning_model.model, \n",
    "                                                  loss_function=ligthning_model.loss)\n",
    "best_model.model.eval()\n",
    "all_predictions, all_true_labels = get_predictions_and_labels(best_model.model, data_val)\n",
    "rmse_val = mean_squared_error(all_true_labels, all_predictions, squared=False)\n",
    "print(f\"RMSE on the validation set: {rmse_val: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(model, dataset, test_group):\n",
    "    all_predictions, all_true_labels = get_predictions_and_labels(model, dataset)\n",
    "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "    qwk = cohen_kappa_score(all_true_labels, all_predictions, weights=\"quadratic\", labels=[0,40,80,120,160,200]) \n",
    "    rmse = mean_squared_error(all_true_labels, all_predictions, squared=False)\n",
    "    horizontal_discrepancy = enem_accuracy_score(all_true_labels, all_predictions)\n",
    "    result = {\n",
    "        'Experiment Reference': EXPERIMENT_NAME,\n",
    "        'Test Group': test_group,\n",
    "        'Competence': REFERENCE_CONCEPT,\n",
    "        'Accuracy': [accuracy],\n",
    "        'RMSE': [rmse],\n",
    "        'QWK': [qwk],\n",
    "        'HDIV': [1- horizontal_discrepancy]\n",
    "    }\n",
    "    return pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_report(model, data_test, data_test_easy, data_test_hard):\n",
    "    result = pd.concat([\n",
    "        compute_metrics(model, data_test, \"full\"),\n",
    "        compute_metrics(model, data_test_easy, \"easy\"),\n",
    "        compute_metrics(model, data_test_hard, \"hard\")\n",
    "    ])\n",
    "    directory = \"experiment_reports\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = f\"{directory}/{EXPERIMENT_NAME}.csv\"\n",
    "    file_exists = os.path.isfile(file_path) and os.path.getsize(file_path) > 0\n",
    "    # if file_exists:\n",
    "         # result.to_csv(file_path, mode='a', header=False, index=False)\n",
    "    # else:\n",
    "        # result.to_csv(file_path, mode='w', header=True, index=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa135e238b7d4d2a8ab0a0595f488fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a3c4eadc2d4b2d96a1c85013b5ab7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e83ca72d6f34058967e10547cd01f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment Reference</th>\n",
       "      <th>Test Group</th>\n",
       "      <th>Competence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>QWK</th>\n",
       "      <th>HDIV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aes_enem_models-sourceA-ordinal-from-sourceB-o...</td>\n",
       "      <td>full</td>\n",
       "      <td>4</td>\n",
       "      <td>0.203704</td>\n",
       "      <td>94.946379</td>\n",
       "      <td>-0.036480</td>\n",
       "      <td>0.351852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aes_enem_models-sourceA-ordinal-from-sourceB-o...</td>\n",
       "      <td>easy</td>\n",
       "      <td>4</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>95.125648</td>\n",
       "      <td>-0.041077</td>\n",
       "      <td>0.338889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aes_enem_models-sourceA-ordinal-from-sourceB-o...</td>\n",
       "      <td>hard</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>94.044907</td>\n",
       "      <td>-0.013582</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Experiment Reference Test Group  Competence  \\\n",
       "0  aes_enem_models-sourceA-ordinal-from-sourceB-o...       full           4   \n",
       "0  aes_enem_models-sourceA-ordinal-from-sourceB-o...       easy           4   \n",
       "0  aes_enem_models-sourceA-ordinal-from-sourceB-o...       hard           4   \n",
       "\n",
       "   Accuracy       RMSE       QWK      HDIV  \n",
       "0  0.203704  94.946379 -0.036480  0.351852  \n",
       "0  0.194444  95.125648 -0.041077  0.338889  \n",
       "0  0.250000  94.044907 -0.013582  0.416667  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_report(best_model.model, data_test, data_test_easy, data_test_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model_checkpoints/hugging_face/finetuning/aes_enem_models-sourceA-ordinal-from-sourceB-ordinal-base-C5'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_save_path = f\"model_checkpoints/hugging_face/finetuning/{EXPERIMENT_NAME}\"\n",
    "bert_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.model.save_pretrained(bert_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc977573f894dc39bfaf4693b8089cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Obtaining predictions:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment Reference</th>\n",
       "      <th>Test Group</th>\n",
       "      <th>Competence</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>QWK</th>\n",
       "      <th>HDIV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aes_enem_models-sourceA-ordinal-from-sourceB-o...</td>\n",
       "      <td>full</td>\n",
       "      <td>4</td>\n",
       "      <td>0.319444</td>\n",
       "      <td>50.184844</td>\n",
       "      <td>0.53211</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Experiment Reference Test Group  Competence  \\\n",
       "0  aes_enem_models-sourceA-ordinal-from-sourceB-o...       full           4   \n",
       "\n",
       "   Accuracy       RMSE      QWK      HDIV  \n",
       "0  0.319444  50.184844  0.53211  0.037037  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            bert_save_path, \n",
    "            cache_dir=\"/tmp/\", \n",
    "            num_labels=6,\n",
    "        )\n",
    "compute_metrics(model, data_test, \"full\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aes_enem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
